#!/usr/bin/python3
# -*- coding: utf-8 -*-
#
# This file is part of pyatc library
#
# Authors:
# Jorge Ibáñez Gijón <jorge.ibannez@uam.es> [2020-2022]
# Departamento de Psicología Básica, Facultad de Psicología
# Universidad Autónoma de Madrid
#
# © Copyright 2022 Jorge Ibáñez Gijón. All rights reserved
#

import os
import glob
import psutil
import multiprocessing as mp

from contextlib import closing
from collections import OrderedDict as OD

from . import util
from .xml import load_xml
from .cometa import compute_cometa
from .parse import run as parse_log

CORE_NUMBER = psutil.cpu_count(logical=False)

############################################################
### NAMES OF THE TASK FILES THAT WILL BE SEARCHED FOR IN
### BATCH PROCESSING MODE.
############################################################

TASKNAMES = [
# Base tasks for first experiment
 'High_12_altDnormal.xml',
 'High_6.xml',
 'Medium_12.xml',
 #'Medium_6.xml',
 'Low_12.xml',
 'Low_6.xml',
 # Derived tasks by flipping spatial dimensions
 # 'High_12_flipy.xml',
 # 'High_12_flipx_flipy.xml',
 # 'High_6_flipx_flipy.xml',
 # 'High_6_flipx.xml',
 # 'High_6_flipy.xml',
 # 'High_12_flipx.xml',
 # 'Medium_12_flipx_flipy.xml',
 # 'Medium_12_flipy.xml',
 # 'Medium_12_flipx.xml',
 # 'Medium_6_flipx_flipy.xml',
 # 'Medium_6_flipx.xml',
 # 'Medium_6_flipy.xml',
 # 'Low_12_flipx_flipy.xml',
 # 'Low_12_flipx.xml',
 # 'Low_12_flipy.xml',
 # 'Low_6_flipx_flipy.xml',
 # 'Low_6_flipy.xml',
 # 'Low_6_flipx.xml',
 ]


def compute_cometa_file(logpath='.', taskpath=None, tmax=600, save2mat=False):
    res = OD()
    res['logpath'] = logpath
    res['taskpath'] = taskpath
    res['tmax'] = tmax

    # Fetch data and model specfications for COMETA compute
    res['taskdict'], res['logdict'], res['flowdict'], res['params'] = util.prepare_data(
        logpath, taskpath, tmax, save2mat)
    res['cometadf'], res['aircrafts_cometa'], res['conflicts'], res['trajectories'] = compute_cometa(
        res['taskdict'], res['logdict'], res['flowdict'], res['params'], save2mat)
    return res


def compute_cometa_dir(logpath='.', taskpath='.', tmax=600, save2mat=False, parallelize=False):
    """Computes the cometa index for all the log files in the target
    directory that match any of the tasks in TASKNAMES global list

    Arguments:
        logpath [string]:
            path that contains the logs generated by pact.exe.

        taskpath [string]:
            path that contains the xml description of the tasks.

        tmax [integer]:
            maximal time for conflict computations. Conflicts ocurring after the
            specified time will not be considered.

        save2mat [boolean]:
            flag to indicate if we want the parsed events in the log to be
            saved in mat files for processing in Matlab.

        parallelize [boolean]:
            flag to indicate if we want to disable parallel computation
            of log files.
    """

    cometa = OD()
    cometa_aircrafts = OD()
    conflicts = OD()
    trjs = OD()
    for taskname in TASKNAMES:
        # Check whether task file exists and load it
        taskfilepath = os.path.join(taskpath,taskname)
        if os.path.isfile(taskfilepath):
            xmlfile = taskname
            taskdict = load_xml(taskfilepath)
        else:
            continue

        print("\n"+"="*60)
        print("\nProcessing log files from task " + taskfilepath)

        # Check whether flows file exists and load it
        flowsname = 'Flows_' + taskname + '.csv'
        flowspath = os.path.join(taskpath, flowsname)
        if os.path.isfile(flowspath):
            flowdict = util.parse_flows_file(flowspath, taskdict)
        else:
            print('Warning, the flows file %s does not exists' % flowspath)
            flowdict = OD()

        # Parse every logdict matching the pattern in dir, compute cometa and store results
        if parallelize == True:
            # First, create a list with all the configurations in advance
            configs = list()
            for logfilepath in glob.iglob(os.path.join(logpath,'*'+taskname+'.log')):
                print("\n\t"+"·"*30)
                print("\tParsing log file " + logfilepath)
                print()
                logfile = os.path.basename(logfilepath)
                logdict = parse_log(logfilepath, save2mat)
                params = util.get_cometa_simulation_parameters(taskdict, flowdict, tmax, logpath, logfile)
                configs.append((logfile, taskdict, logdict, flowdict, params, save2mat))

            # Run in parallel the worker function
            res = runparallel(_cometa_worker, configs)

            # Store the results
            for (logfile, tr_cometa, tr_cometa_aircrafts, tr_conflicts, tr_trjs) in res:
                cometa[logfile] = tr_cometa
                cometa_aircrafts[logfile] = tr_cometa_aircrafts
                conflicts[logfile] = tr_conflicts
                trjs[logfile] = tr_trjs
        else:
            for logfilepath in glob.iglob(os.path.join(logpath,'*'+taskname+'.log')):
                print("\n\t"+"·"*30)
                print("\tParsing log file " + logfilepath)
                print()
                logfile = os.path.basename(logfilepath)
                logdict = parse_log(logfilepath, save2mat)
                params = util.get_cometa_simulation_parameters(taskdict, flowdict, tmax, logpath, logfile)
                #print("Processing log file " + logpath)
                (cometa[logfile], cometa_aircrafts[logfile], conflicts[logfile], trjs[logfile]) = \
                    compute_cometa(taskdict, logdict, flowdict, params, save2mat)

    return cometa, cometa_aircrafts, conflicts, trjs


def compute_cometa_exp(logpath='.', taskpath='.', tmax=600, save2mat=False):
    """Runs COMETA computation in all participants of experiment. It is assumed
    that the data directory contains one directory per participant labeled
    with a capital P and 3 digits that identify it.
    """
    cometa = OD()
    cometa_aircrafts = OD()
    conflicts = OD()
    trjs = OD()
    #######################################################
    # Iterate over all participant directories
    #######################################################
    for ppdir in sorted(glob.iglob(os.path.join(logpath,'P*'))):
        ppname = os.path.basename(ppdir)

        pppath = os.path.join(ppdir,'Simulador')
        print(pppath)
        if os.path.exists(pppath):
            ppdir = pppath
        print()
        print('='*60)
        print('  Parsing logs and computing COMETA for ' + ppname)
        print('='*60)
        print()
        (cometa[ppname], cometa_aircrafts[ppname], conflicts[ppname], trjs[ppname]) = \
            compute_cometa_pp(pppath, taskpath, tmax, save2mat)
    return cometa, cometa_aircrafts, conflicts, trjs


def compute_cometa_exp_parallel(logpath='.', taskpath='.', tmax=600, save2mat=False):
    """Runs COMETA computation in all participants of experiment. It is assumed
    that the data directory contains one directory per participant labeled
    with a capital P and 3 digits that identify it.
    """
    cometa = OD()
    cometa_aircrafts = OD()
    conflicts = OD()
    trjs = OD()

    # Create configurations
    configs = list()
    for ppdir in sorted(glob.iglob(os.path.join(logpath,'P*'))):
        ppname = os.path.basename(ppdir)
        pppath = os.path.join(ppdir,'Simulador')
        if os.path.exists(pppath):
            ppdir = pppath
            configs.append((ppname, pppath, taskpath, tmax, save2mat))

    # Run the parallel computations
    res = runparallel(_worker_compute_cometa_pp, configs)

    # Store the results
    for (ppname, tr_cometa, tr_cometa_aircrafts, tr_conflicts, tr_trjs) in res:
        cometa[ppname] = tr_cometa
        cometa_aircrafts[ppname] = tr_cometa_aircrafts
        conflicts[ppname] = tr_conflicts
        trjs[ppname] = tr_trjs

    return cometa, cometa_aircrafts, conflicts, trjs


def _worker_compute_cometa_pp(config):
    (ppname, logpath, taskpath, tmax, save2mat) = config
    return (ppname,) + compute_cometa_pp(logpath, taskpath, tmax, save2mat)


def compute_cometa_pp(logpath='.', taskpath='.', tmax=600, save2mat=False, pasive=False):
    """Computes the cometa index for all the log files in the participant
    directory. Each condition in the log files must match one of the tasks
    in TASKNAMES global list, or the program will yield a warning.

    Arguments:
        logpath [string]:
            path that contains the logs generated by pact.exe.

        taskpath [string]:
            path that contains the xml description of the tasks.

        tmax [integer]:
            maximal time for conflict computations. Conflicts ocurring after the
            specified time will not be considered.

        save2mat [boolean]:
            flag to indicate if we want the parsed events in the log to be
            saved in mat files for processing in Matlab.

        parallelize [boolean]:
            flag to indicate if we want to disable parallel computation
            of log files.
    """

    cometa = OD()
    cometa_aircrafts = OD()
    conflicts = OD()
    trjs = OD()
    #######################################################
    # Iterate over all log files found in logpath
    #######################################################
    for logfilepath in sorted(glob.iglob(os.path.join(logpath,'*.xml.log'))):
        print("\n\t"+"*"*50)
        print("\tPROCESSING FILE: " + logfilepath)
        print("\t"+"*"*50)

        # Create path and filename string variables
        logfilename = os.path.basename(logfilepath)
        try:
            if pasive:
                taskname = logfilename.split('.')[0]
            else:
                #[taskname, ppno] = logfilename.split('.')[0].split('_')
                taskname = logfilename.split('.')[0]
        except:
            print('\t[ERROR] Wrong naming convention in log file ' + logfilename)
            if pasive:
                print('\t\tExpected convention is TASKNAME.xml.log')
            else:
                print('\t\tExpected convention is TASKNAME_PPNAME.xml.log')
            print('\t\tReview the name of the file and run again. Skipping...')
            continue

        taskname = taskname + '.xml'
        taskfilepath = os.path.join(taskpath,taskname)
        flowsname = 'Flows_' + taskname + '.csv'
        flowspath = os.path.join(taskpath, flowsname)

        # Load task
        print("\n\t"+"-"*30)
        print("\tParsing task file " + taskfilepath)
        if os.path.isfile(taskfilepath):
            xmlfile = taskname
            taskdict = load_xml(taskfilepath)
        else:
            print('\t[ERROR] Task file not found!!')
            continue

        # Load flows file
        print("\n\t"+"·"*30)
        print("\tParsing flows file " + flowspath)
        if os.path.isfile(flowspath):
            flowdict = util.parse_flows_file(flowspath, taskdict)
        else:
            print('\tWarning, the flows file %s does not exists' % flowspath)
            flowdict = OD()

        # Parse log
        print("\n\t"+"·"*30)
        print("\tParsing log file " + logfilepath)
        print()
        logdict = parse_log(logfilepath, save2mat)

        # Get sky parameters for cometa computation
        params = util.get_sky_parameters(taskdict, flowdict, tmax, logpath, logfilename)

        # Perform the actual cometa computation
        (cometa[logfilename], cometa_aircrafts[logfilename], conflicts[logfilename], trjs[logfilename]) = \
            compute_cometa(taskdict, logdict, flowdict, params, save2mat)

    return cometa, cometa_aircrafts, conflicts, trjs


def compute_cometa_pasive(logpath='.', taskpath='.', tmax=600, save2mat=False):
    return compute_cometa_pp(logpath, taskpath, tmax, save2mat, pasive=True)


def _cometa_worker(config):
    """Private function that implements the worker that will be used in parallel
    computation of cometa files in batch processing mode"""
    (logfile, taskdict, logdict, flowdict, params, save2mat) = config
    #print("Parallel processing of logfile " + logfile)
    cometa, cometa_aircrafts, conflicts, trjs = \
        compute_cometa(taskdict, logdict, flowdict, params, save2mat)
    return (logfile, cometa, cometa_aircrafts, conflicts, trjs)


"""
------------------------------------------------------------------------
    EXTERNAL API PARALLELIZED FUNCTIONS
------------------------------------------------------------------------
"""

def runparallel(fcn, configs):
    """
    """
    return _runparallel_pool(fcn, configs)


def runparallel_sorted(fcn, configs, rev=False):
    """
    """
    # Fetch results by any of the methods below
    results = _runparallel_pool(fcn, configs)
    # Short the list and return
    results.sort(key=lambda x: x[0], reverse=rev)
    return results


def runparallel_async(fcn, configs):
    """
    """
    return _runparallel_pool_async(fcn, configs)


"""
------------------------------------------------------------------------
    Actual compute methods
------------------------------------------------------------------------
"""

def _runparallel_pool(fcn, configs, WRKs=CORE_NUMBER, max_tasks=1):
    # Multiprocessing Pool backend. It fails to pickle lambda functions,
    # and therefore, should be replaced by an alternative backend
    # (pathos most likely) when a python 3 compatible version is released
    with closing(mp.Pool(processes=WRKs, maxtasksperchild=max_tasks)) as pool:
        results = pool.map(fcn, configs)
        pool.close()
        pool.join()
        pool.terminate()
        #pool.clear()
    return results


def _runparallel_pool_async(fcn, configs, WRKs=CORE_NUMBER, max_tasks=1):
    # asyn execution of lambda
    with closing(mp.Pool(processes=WRKs, maxtasksperchild=max_tasks)) as pool:
        jobs = [pool.apply_async(fcn, conf) for conf in configs]
        results = [job.get() for job in jobs]
    return results


